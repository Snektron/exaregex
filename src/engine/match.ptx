//
// Generated by LLVM NVPTX Back-End
//

.version 7.0
.target sm_80
.address_size 64

	// .globl	initial
.shared .align 4 .b8 match_$_initial_storage[15172];

.visible .entry initial(
	.param .u64 initial_param_0,
	.param .u64 initial_param_1,
	.param .u32 initial_param_2,
	.param .u64 initial_param_3,
	.param .u32 initial_param_4,
	.param .u64 initial_param_5,
	.param .u64 initial_param_6
)
{
	.local .align 1 .b8 	__local_depot0[96];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<42>;
	.reg .b16 	%rs<127>;
	.reg .b32 	%r<178>;
	.reg .b64 	%rd<278>;

	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r22, [initial_param_2];
	add.u64 	%rd39, %SP, 0;
	mov.u32 	%r1, %tid.x;
	setp.gt.u32 	%p1, %r1, 255;
	cvt.u64.u32 	%rd4, %r1;
	mov.u64 	%rd42, match_$_initial_storage;
	@%p1 bra 	$L__BB0_2;
	ld.param.u64 	%rd38, [initial_param_0];
	add.s64 	%rd43, %rd42, %rd4;
	add.s64 	%rd5, %rd43, 4;
	add.s64 	%rd6, %rd38, %rd4;
	ld.global.u8 	%rs56, [%rd6];
	st.shared.u8 	[%rd5], %rs56;
$L__BB0_2:
	add.u64 	%rd40, %SP, 32;
	add.u64 	%rd41, %SP, 64;
	ld.param.u32 	%r23, [initial_param_4];
	ld.param.u64 	%rd35, [initial_param_3];
	cvta.to.local.u64 	%rd1, %rd39;
	mul.lo.s32 	%r2, %r22, %r22;
	setp.ge.u32 	%p2, %r1, %r2;
	@%p2 bra 	$L__BB0_5;
	ld.param.u64 	%rd34, [initial_param_1];
	add.s64 	%rd273, %rd34, %rd4;
	add.s64 	%rd45, %rd4, %rd42;
	add.s64 	%rd272, %rd45, 260;
	mov.u32 	%r177, %r1;
$L__BB0_4:
	ld.global.u8 	%rs57, [%rd273];
	st.shared.u8 	[%rd272], %rs57;
	add.s32 	%r177, %r177, 512;
	add.s64 	%rd273, %rd273, 512;
	add.s64 	%rd272, %rd272, 512;
	setp.lt.u32 	%p3, %r177, %r2;
	@%p3 bra 	$L__BB0_4;
$L__BB0_5:
	ld.param.u64 	%rd37, [initial_param_6];
	ld.param.u64 	%rd36, [initial_param_5];
	cvta.to.local.u64 	%rd2, %rd40;
	cvta.to.local.u64 	%rd3, %rd41;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	add.s64 	%rd47, %rd42, 14660;
	add.s64 	%rd13, %rd47, %rd4;
	add.s32 	%r5, %r1, 1;
	add.s32 	%r6, %r1, 2;
	add.s32 	%r7, %r1, 4;
	add.s32 	%r8, %r1, 8;
	add.s32 	%r9, %r1, 16;
	add.s32 	%r10, %r1, 32;
	add.s32 	%r11, %r1, 64;
	add.s32 	%r12, %r1, 128;
	or.b32  	%r24, %r1, 256;
	cvt.u64.u32 	%rd48, %r24;
	add.s64 	%rd14, %rd47, %rd48;
	cvt.u64.u32 	%rd15, %r23;
	add.s32 	%r13, %r23, 31;
	add.s32 	%r14, %r1, 256;
	shl.b32 	%r15, %r1, 5;
	add.s64 	%rd16, %rd35, 1;
	add.s64 	%rd17, %rd1, 2;
	setp.eq.s32 	%p4, %r1, 0;
	setp.lt.u32 	%p8, %r1, 511;
	setp.lt.u32 	%p9, %r1, 510;
	setp.lt.u32 	%p10, %r1, 508;
$L__BB0_6:
	@%p4 bra 	$L__BB0_66;
	bra.uni 	$L__BB0_7;
$L__BB0_66:
	mov.b32 	%r25, 1;
	{ 
	.reg 	.s32 temp; 
	neg.s32 	temp, %r25; 
	atom.global.add.u32 	%r26, [%rd37], temp; 
	}
	st.volatile.shared.u32 	[match_$_initial_storage], %r26;
	ld.local.u8 	%rs3, [%rd3];
	bra.uni 	$L__BB0_7;
$L__BB0_39:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs104;
	// begin inline asm
	bar.sync 0;
	// end inline asm
$L__BB0_40:
	@%p4 bra 	$L__BB0_41;
$L__BB0_7:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	ld.volatile.shared.u32 	%r16, [match_$_initial_storage];
	setp.lt.s32 	%p5, %r16, 1;
	@%p5 bra 	$L__BB0_8;
	add.s32 	%r17, %r16, -1;
	shl.b32 	%r27, %r16, 14;
	setp.le.u32 	%p6, %r27, %r23;
	shl.b32 	%r18, %r17, 14;
	add.s32 	%r28, %r18, %r15;
	cvt.u64.u32 	%rd18, %r28;
	@%p6 bra 	$L__BB0_27;
	add.s64 	%rd19, %rd16, %rd18;
	mov.u64 	%rd275, 0;
	bra.uni 	$L__BB0_11;
$L__BB0_18:
	add.s64 	%rd275, %rd275, 4;
	setp.ne.s64 	%p21, %rd275, 32;
	@%p21 bra 	$L__BB0_11;
	bra.uni 	$L__BB0_19;
$L__BB0_11:
	add.s64 	%rd24, %rd18, %rd275;
	setp.lt.u64 	%p17, %rd24, %rd15;
	add.s64 	%rd25, %rd19, %rd275;
	add.s64 	%rd26, %rd2, %rd275;
	@%p17 bra 	$L__BB0_75;
	bra.uni 	$L__BB0_12;
$L__BB0_75:
	ld.global.u8 	%rs90, [%rd25+-1];
	st.local.u8 	[%rd26], %rs90;
$L__BB0_12:
	add.s64 	%rd188, %rd24, 1;
	setp.ge.u64 	%p18, %rd188, %rd15;
	@%p18 bra 	$L__BB0_14;
	ld.global.u8 	%rs91, [%rd25];
	st.local.u8 	[%rd26+1], %rs91;
$L__BB0_14:
	add.s64 	%rd189, %rd24, 2;
	setp.ge.u64 	%p19, %rd189, %rd15;
	@%p19 bra 	$L__BB0_16;
	ld.global.u8 	%rs92, [%rd25+1];
	st.local.u8 	[%rd26+2], %rs92;
$L__BB0_16:
	add.s64 	%rd190, %rd24, 3;
	setp.ge.u64 	%p20, %rd190, %rd15;
	@%p20 bra 	$L__BB0_18;
	ld.global.u8 	%rs93, [%rd25+2];
	st.local.u8 	[%rd26+3], %rs93;
	bra.uni 	$L__BB0_18;
$L__BB0_27:
	mov.u64 	%rd274, 0;
	add.s64 	%rd50, %rd35, %rd18;
	ld.global.v4.u32 	{%r29, %r30, %r31, %r32}, [%rd50];
	bfe.s32 	%r37, %r29, 0, 8;
	bfe.s32 	%r38, %r29, 8, 8;
	bfe.s32 	%r39, %r29, 16, 8;
	bfe.s32 	%r40, %r29, 24, 8;
	bfe.s32 	%r41, %r30, 0, 8;
	bfe.s32 	%r42, %r30, 8, 8;
	bfe.s32 	%r43, %r30, 16, 8;
	bfe.s32 	%r44, %r30, 24, 8;
	bfe.s32 	%r45, %r31, 0, 8;
	bfe.s32 	%r46, %r31, 8, 8;
	bfe.s32 	%r47, %r31, 16, 8;
	bfe.s32 	%r48, %r31, 24, 8;
	bfe.s32 	%r49, %r32, 0, 8;
	bfe.s32 	%r50, %r32, 8, 8;
	bfe.s32 	%r51, %r32, 16, 8;
	bfe.s32 	%r52, %r32, 24, 8;
	ld.global.v4.u32 	{%r53, %r54, %r55, %r56}, [%rd50+16];
	bfe.s32 	%r61, %r53, 0, 8;
	bfe.s32 	%r62, %r53, 8, 8;
	bfe.s32 	%r63, %r53, 16, 8;
	bfe.s32 	%r64, %r53, 24, 8;
	bfe.s32 	%r65, %r54, 0, 8;
	bfe.s32 	%r66, %r54, 8, 8;
	bfe.s32 	%r67, %r54, 16, 8;
	bfe.s32 	%r68, %r54, 24, 8;
	bfe.s32 	%r69, %r55, 0, 8;
	bfe.s32 	%r70, %r55, 8, 8;
	bfe.s32 	%r71, %r55, 16, 8;
	bfe.s32 	%r72, %r55, 24, 8;
	bfe.s32 	%r73, %r56, 0, 8;
	bfe.s32 	%r74, %r56, 8, 8;
	bfe.s32 	%r75, %r56, 16, 8;
	bfe.s32 	%r76, %r56, 24, 8;
	cvt.u64.u32 	%rd51, %r37;
	and.b64  	%rd52, %rd51, 255;
	add.s64 	%rd54, %rd42, 4;
	add.s64 	%rd55, %rd54, %rd52;
	ld.shared.u8 	%rs3, [%rd55];
	cvt.u64.u32 	%rd56, %r38;
	and.b64  	%rd57, %rd56, 255;
	add.s64 	%rd58, %rd54, %rd57;
	ld.shared.u8 	%rs59, [%rd58];
	st.local.u8 	[%rd3+1], %rs59;
	cvt.u64.u32 	%rd59, %r39;
	and.b64  	%rd60, %rd59, 255;
	add.s64 	%rd61, %rd54, %rd60;
	ld.shared.u8 	%rs60, [%rd61];
	st.local.u8 	[%rd3+2], %rs60;
	cvt.u64.u32 	%rd62, %r40;
	and.b64  	%rd63, %rd62, 255;
	add.s64 	%rd64, %rd54, %rd63;
	ld.shared.u8 	%rs61, [%rd64];
	st.local.u8 	[%rd3+3], %rs61;
	cvt.u64.u32 	%rd65, %r41;
	and.b64  	%rd66, %rd65, 255;
	add.s64 	%rd67, %rd54, %rd66;
	ld.shared.u8 	%rs62, [%rd67];
	st.local.u8 	[%rd3+4], %rs62;
	cvt.u64.u32 	%rd68, %r42;
	and.b64  	%rd69, %rd68, 255;
	add.s64 	%rd70, %rd54, %rd69;
	ld.shared.u8 	%rs63, [%rd70];
	st.local.u8 	[%rd3+5], %rs63;
	cvt.u64.u32 	%rd71, %r43;
	and.b64  	%rd72, %rd71, 255;
	add.s64 	%rd73, %rd54, %rd72;
	ld.shared.u8 	%rs64, [%rd73];
	st.local.u8 	[%rd3+6], %rs64;
	cvt.u64.u32 	%rd74, %r44;
	and.b64  	%rd75, %rd74, 255;
	add.s64 	%rd76, %rd54, %rd75;
	ld.shared.u8 	%rs65, [%rd76];
	st.local.u8 	[%rd3+7], %rs65;
	cvt.u64.u32 	%rd77, %r45;
	and.b64  	%rd78, %rd77, 255;
	add.s64 	%rd79, %rd54, %rd78;
	ld.shared.u8 	%rs66, [%rd79];
	st.local.u8 	[%rd3+8], %rs66;
	cvt.u64.u32 	%rd80, %r46;
	and.b64  	%rd81, %rd80, 255;
	add.s64 	%rd82, %rd54, %rd81;
	ld.shared.u8 	%rs67, [%rd82];
	st.local.u8 	[%rd3+9], %rs67;
	cvt.u64.u32 	%rd83, %r47;
	and.b64  	%rd84, %rd83, 255;
	add.s64 	%rd85, %rd54, %rd84;
	ld.shared.u8 	%rs68, [%rd85];
	st.local.u8 	[%rd3+10], %rs68;
	cvt.u64.u32 	%rd86, %r48;
	and.b64  	%rd87, %rd86, 255;
	add.s64 	%rd88, %rd54, %rd87;
	ld.shared.u8 	%rs69, [%rd88];
	st.local.u8 	[%rd3+11], %rs69;
	cvt.u64.u32 	%rd89, %r49;
	and.b64  	%rd90, %rd89, 255;
	add.s64 	%rd91, %rd54, %rd90;
	ld.shared.u8 	%rs70, [%rd91];
	st.local.u8 	[%rd3+12], %rs70;
	cvt.u64.u32 	%rd92, %r50;
	and.b64  	%rd93, %rd92, 255;
	add.s64 	%rd94, %rd54, %rd93;
	ld.shared.u8 	%rs71, [%rd94];
	st.local.u8 	[%rd3+13], %rs71;
	cvt.u64.u32 	%rd95, %r51;
	and.b64  	%rd96, %rd95, 255;
	add.s64 	%rd97, %rd54, %rd96;
	ld.shared.u8 	%rs72, [%rd97];
	st.local.u8 	[%rd3+14], %rs72;
	cvt.u64.u32 	%rd98, %r52;
	and.b64  	%rd99, %rd98, 255;
	add.s64 	%rd100, %rd54, %rd99;
	ld.shared.u8 	%rs73, [%rd100];
	st.local.u8 	[%rd3+15], %rs73;
	cvt.u64.u32 	%rd101, %r61;
	and.b64  	%rd102, %rd101, 255;
	add.s64 	%rd103, %rd54, %rd102;
	ld.shared.u8 	%rs74, [%rd103];
	st.local.u8 	[%rd3+16], %rs74;
	cvt.u64.u32 	%rd104, %r62;
	and.b64  	%rd105, %rd104, 255;
	add.s64 	%rd106, %rd54, %rd105;
	ld.shared.u8 	%rs75, [%rd106];
	st.local.u8 	[%rd3+17], %rs75;
	cvt.u64.u32 	%rd107, %r63;
	and.b64  	%rd108, %rd107, 255;
	add.s64 	%rd109, %rd54, %rd108;
	ld.shared.u8 	%rs76, [%rd109];
	st.local.u8 	[%rd3+18], %rs76;
	cvt.u64.u32 	%rd110, %r64;
	and.b64  	%rd111, %rd110, 255;
	add.s64 	%rd112, %rd54, %rd111;
	ld.shared.u8 	%rs77, [%rd112];
	st.local.u8 	[%rd3+19], %rs77;
	cvt.u64.u32 	%rd113, %r65;
	and.b64  	%rd114, %rd113, 255;
	add.s64 	%rd115, %rd54, %rd114;
	ld.shared.u8 	%rs78, [%rd115];
	st.local.u8 	[%rd3+20], %rs78;
	cvt.u64.u32 	%rd116, %r66;
	and.b64  	%rd117, %rd116, 255;
	add.s64 	%rd118, %rd54, %rd117;
	ld.shared.u8 	%rs79, [%rd118];
	st.local.u8 	[%rd3+21], %rs79;
	cvt.u64.u32 	%rd119, %r67;
	and.b64  	%rd120, %rd119, 255;
	add.s64 	%rd121, %rd54, %rd120;
	ld.shared.u8 	%rs80, [%rd121];
	st.local.u8 	[%rd3+22], %rs80;
	cvt.u64.u32 	%rd122, %r68;
	and.b64  	%rd123, %rd122, 255;
	add.s64 	%rd124, %rd54, %rd123;
	ld.shared.u8 	%rs81, [%rd124];
	st.local.u8 	[%rd3+23], %rs81;
	cvt.u64.u32 	%rd125, %r69;
	and.b64  	%rd126, %rd125, 255;
	add.s64 	%rd127, %rd54, %rd126;
	ld.shared.u8 	%rs82, [%rd127];
	st.local.u8 	[%rd3+24], %rs82;
	cvt.u64.u32 	%rd128, %r70;
	and.b64  	%rd129, %rd128, 255;
	add.s64 	%rd130, %rd54, %rd129;
	ld.shared.u8 	%rs83, [%rd130];
	st.local.u8 	[%rd3+25], %rs83;
	cvt.u64.u32 	%rd131, %r71;
	and.b64  	%rd132, %rd131, 255;
	add.s64 	%rd133, %rd54, %rd132;
	ld.shared.u8 	%rs84, [%rd133];
	st.local.u8 	[%rd3+26], %rs84;
	cvt.u64.u32 	%rd134, %r72;
	and.b64  	%rd135, %rd134, 255;
	add.s64 	%rd136, %rd54, %rd135;
	ld.shared.u8 	%rs85, [%rd136];
	st.local.u8 	[%rd3+27], %rs85;
	cvt.u64.u32 	%rd137, %r73;
	and.b64  	%rd138, %rd137, 255;
	add.s64 	%rd139, %rd54, %rd138;
	ld.shared.u8 	%rs86, [%rd139];
	st.local.u8 	[%rd3+28], %rs86;
	cvt.u64.u32 	%rd140, %r74;
	and.b64  	%rd141, %rd140, 255;
	add.s64 	%rd142, %rd54, %rd141;
	ld.shared.u8 	%rs87, [%rd142];
	st.local.u8 	[%rd3+29], %rs87;
	cvt.u64.u32 	%rd143, %r75;
	and.b64  	%rd144, %rd143, 255;
	add.s64 	%rd145, %rd54, %rd144;
	ld.shared.u8 	%rs88, [%rd145];
	st.local.u8 	[%rd3+30], %rs88;
	cvt.u64.u32 	%rd146, %r76;
	and.b64  	%rd147, %rd146, 255;
	add.s64 	%rd148, %rd54, %rd147;
	ld.shared.u8 	%rs89, [%rd148];
	st.local.u8 	[%rd3+31], %rs89;
	mov.u16 	%rs103, %rs3;
$L__BB0_28:
	add.s64 	%rd21, %rd3, %rd274;
	ld.local.u8 	%r77, [%rd21+1];
	cvt.u32.u16 	%r78, %rs103;
	and.b32  	%r79, %r78, 255;
	mad.lo.s32 	%r80, %r79, %r22, %r77;
	cvt.u64.u32 	%rd149, %r80;
	add.s64 	%rd151, %rd42, 260;
	add.s64 	%rd152, %rd151, %rd149;
	ld.shared.u8 	%r81, [%rd152];
	ld.local.u8 	%r82, [%rd21+2];
	mad.lo.s32 	%r83, %r81, %r22, %r82;
	cvt.u64.u32 	%rd153, %r83;
	add.s64 	%rd154, %rd151, %rd153;
	ld.shared.u8 	%r84, [%rd154];
	ld.local.u8 	%r85, [%rd21+3];
	mad.lo.s32 	%r86, %r84, %r22, %r85;
	cvt.u64.u32 	%rd155, %r86;
	add.s64 	%rd156, %rd151, %rd155;
	ld.shared.u8 	%rs104, [%rd156];
	cvt.u32.u16 	%r87, %rs104;
	and.b32  	%r19, %r87, 255;
	setp.eq.s64 	%p7, %rd274, 28;
	@%p7 bra 	$L__BB0_30;
	add.s64 	%rd274, %rd274, 4;
	ld.local.u8 	%r88, [%rd21+4];
	mad.lo.s32 	%r89, %r19, %r22, %r88;
	cvt.u64.u32 	%rd157, %r89;
	add.s64 	%rd159, %rd42, %rd157;
	ld.shared.u8 	%rs103, [%rd159+260];
	bra.uni 	$L__BB0_28;
$L__BB0_19:
	mov.u64 	%rd28, 0;
	bra.uni 	$L__BB0_20;
$L__BB0_43:
	add.s64 	%rd28, %rd28, 4;
	setp.eq.s64 	%p26, %rd28, 32;
	@%p26 bra 	$L__BB0_44;
$L__BB0_20:
	add.s64 	%rd29, %rd18, %rd28;
	setp.lt.u64 	%p22, %rd29, %rd15;
	add.s64 	%rd270, %rd1, %rd28;
	add.s64 	%rd271, %rd2, %rd28;
	@%p22 bra 	$L__BB0_76;
	bra.uni 	$L__BB0_21;
$L__BB0_76:
	ld.local.u8 	%rd194, [%rd271];
	add.s64 	%rd196, %rd42, %rd194;
	ld.shared.u8 	%rs94, [%rd196+4];
	st.local.u8 	[%rd270], %rs94;
$L__BB0_21:
	add.s64 	%rd197, %rd29, 1;
	setp.ge.u64 	%p23, %rd197, %rd15;
	@%p23 bra 	$L__BB0_23;
	ld.local.u8 	%rd200, [%rd271+1];
	add.s64 	%rd202, %rd42, %rd200;
	ld.shared.u8 	%rs95, [%rd202+4];
	st.local.u8 	[%rd270+1], %rs95;
$L__BB0_23:
	add.s64 	%rd203, %rd29, 2;
	setp.ge.u64 	%p24, %rd203, %rd15;
	@%p24 bra 	$L__BB0_25;
	ld.local.u8 	%rd206, [%rd271+2];
	add.s64 	%rd208, %rd42, %rd206;
	ld.shared.u8 	%rs96, [%rd208+4];
	st.local.u8 	[%rd270+2], %rs96;
$L__BB0_25:
	add.s64 	%rd209, %rd29, 3;
	setp.ge.u64 	%p25, %rd209, %rd15;
	@%p25 bra 	$L__BB0_43;
	ld.local.u8 	%rd212, [%rd271+3];
	add.s64 	%rd214, %rd42, %rd212;
	ld.shared.u8 	%rs97, [%rd214+4];
	st.local.u8 	[%rd270+3], %rs97;
	bra.uni 	$L__BB0_43;
$L__BB0_30:
	st.shared.u8 	[%rd13], %rs104;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	@%p8 bra 	$L__BB0_67;
	bra.uni 	$L__BB0_31;
$L__BB0_67:
	ld.shared.u8 	%r90, [%rd13+1];
	mad.lo.s32 	%r91, %r19, %r22, %r90;
	cvt.u64.u32 	%rd160, %r91;
	add.s64 	%rd162, %rd42, %rd160;
	ld.shared.u8 	%rs104, [%rd162+260];
$L__BB0_31:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs104;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	@%p9 bra 	$L__BB0_68;
	bra.uni 	$L__BB0_32;
$L__BB0_68:
	ld.shared.u8 	%r92, [%rd13+2];
	cvt.u32.u16 	%r93, %rs104;
	and.b32  	%r94, %r93, 255;
	mad.lo.s32 	%r95, %r94, %r22, %r92;
	cvt.u64.u32 	%rd163, %r95;
	add.s64 	%rd165, %rd42, %rd163;
	ld.shared.u8 	%rs104, [%rd165+260];
$L__BB0_32:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs104;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	@%p10 bra 	$L__BB0_69;
	bra.uni 	$L__BB0_33;
$L__BB0_69:
	ld.shared.u8 	%r96, [%rd13+4];
	cvt.u32.u16 	%r97, %rs104;
	and.b32  	%r98, %r97, 255;
	mad.lo.s32 	%r99, %r98, %r22, %r96;
	cvt.u64.u32 	%rd166, %r99;
	add.s64 	%rd168, %rd42, %rd166;
	ld.shared.u8 	%rs104, [%rd168+260];
$L__BB0_33:
	setp.lt.u32 	%p11, %r1, 504;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs104;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	@%p11 bra 	$L__BB0_70;
	bra.uni 	$L__BB0_34;
$L__BB0_70:
	ld.shared.u8 	%r100, [%rd13+8];
	cvt.u32.u16 	%r101, %rs104;
	and.b32  	%r102, %r101, 255;
	mad.lo.s32 	%r103, %r102, %r22, %r100;
	cvt.u64.u32 	%rd169, %r103;
	add.s64 	%rd171, %rd42, %rd169;
	ld.shared.u8 	%rs104, [%rd171+260];
$L__BB0_34:
	setp.lt.u32 	%p12, %r1, 496;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs104;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	@%p12 bra 	$L__BB0_71;
	bra.uni 	$L__BB0_35;
$L__BB0_71:
	ld.shared.u8 	%r104, [%rd13+16];
	cvt.u32.u16 	%r105, %rs104;
	and.b32  	%r106, %r105, 255;
	mad.lo.s32 	%r107, %r106, %r22, %r104;
	cvt.u64.u32 	%rd172, %r107;
	add.s64 	%rd174, %rd42, %rd172;
	ld.shared.u8 	%rs104, [%rd174+260];
$L__BB0_35:
	setp.lt.u32 	%p13, %r1, 480;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs104;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	@%p13 bra 	$L__BB0_72;
	bra.uni 	$L__BB0_36;
$L__BB0_72:
	ld.shared.u8 	%r108, [%rd13+32];
	cvt.u32.u16 	%r109, %rs104;
	and.b32  	%r110, %r109, 255;
	mad.lo.s32 	%r111, %r110, %r22, %r108;
	cvt.u64.u32 	%rd175, %r111;
	add.s64 	%rd177, %rd42, %rd175;
	ld.shared.u8 	%rs104, [%rd177+260];
$L__BB0_36:
	setp.lt.u32 	%p14, %r1, 448;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs104;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	@%p14 bra 	$L__BB0_73;
	bra.uni 	$L__BB0_37;
$L__BB0_73:
	ld.shared.u8 	%r112, [%rd13+64];
	cvt.u32.u16 	%r113, %rs104;
	and.b32  	%r114, %r113, 255;
	mad.lo.s32 	%r115, %r114, %r22, %r112;
	cvt.u64.u32 	%rd178, %r115;
	add.s64 	%rd180, %rd42, %rd178;
	ld.shared.u8 	%rs104, [%rd180+260];
$L__BB0_37:
	setp.lt.u32 	%p15, %r1, 384;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs104;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	@%p15 bra 	$L__BB0_74;
	bra.uni 	$L__BB0_38;
$L__BB0_74:
	ld.shared.u8 	%r116, [%rd13+128];
	cvt.u32.u16 	%r117, %rs104;
	and.b32  	%r118, %r117, 255;
	mad.lo.s32 	%r119, %r118, %r22, %r116;
	cvt.u64.u32 	%rd181, %r119;
	add.s64 	%rd183, %rd42, %rd181;
	ld.shared.u8 	%rs104, [%rd183+260];
$L__BB0_38:
	setp.lt.u32 	%p16, %r1, 256;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs104;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	@%p16 bra 	$L__BB0_42;
	bra.uni 	$L__BB0_39;
$L__BB0_42:
	ld.shared.u8 	%r120, [%rd14];
	cvt.u32.u16 	%r121, %rs104;
	and.b32  	%r122, %r121, 255;
	mad.lo.s32 	%r123, %r122, %r22, %r120;
	cvt.u64.u32 	%rd184, %r123;
	add.s64 	%rd186, %rd42, %rd184;
	ld.shared.u8 	%rs104, [%rd186+260];
	bra.uni 	$L__BB0_39;
$L__BB0_44:
	ld.local.u8 	%rs118, [%rd1];
	mov.u64 	%rd31, 0;
	bra.uni 	$L__BB0_45;
$L__BB0_53:
	add.s64 	%rd31, %rd31, 4;
$L__BB0_45:
	add.s64 	%rd32, %rd18, %rd31;
	add.s64 	%rd216, %rd32, 1;
	setp.lt.u64 	%p27, %rd216, %rd15;
	@%p27 bra 	$L__BB0_54;
	bra.uni 	$L__BB0_46;
$L__BB0_54:
	add.s64 	%rd217, %rd17, %rd31;
	ld.local.u8 	%r124, [%rd217+-1];
	cvt.u32.u16 	%r125, %rs118;
	and.b32  	%r126, %r125, 255;
	mad.lo.s32 	%r127, %r126, %r22, %r124;
	cvt.u64.u32 	%rd218, %r127;
	add.s64 	%rd220, %rd42, %rd218;
	ld.shared.u8 	%rs118, [%rd220+260];
$L__BB0_46:
	add.s64 	%rd221, %rd32, 2;
	setp.ge.u64 	%p28, %rd221, %rd15;
	@%p28 bra 	$L__BB0_48;
	add.s64 	%rd222, %rd17, %rd31;
	ld.local.u8 	%r128, [%rd222];
	cvt.u32.u16 	%r129, %rs118;
	and.b32  	%r130, %r129, 255;
	mad.lo.s32 	%r131, %r130, %r22, %r128;
	cvt.u64.u32 	%rd223, %r131;
	add.s64 	%rd225, %rd42, %rd223;
	ld.shared.u8 	%rs118, [%rd225+260];
$L__BB0_48:
	add.s64 	%rd226, %rd32, 3;
	setp.ge.u64 	%p29, %rd226, %rd15;
	@%p29 bra 	$L__BB0_50;
	add.s64 	%rd227, %rd17, %rd31;
	ld.local.u8 	%r132, [%rd227+1];
	cvt.u32.u16 	%r133, %rs118;
	and.b32  	%r134, %r133, 255;
	mad.lo.s32 	%r135, %r134, %r22, %r132;
	cvt.u64.u32 	%rd228, %r135;
	add.s64 	%rd230, %rd42, %rd228;
	ld.shared.u8 	%rs118, [%rd230+260];
$L__BB0_50:
	setp.eq.s64 	%p30, %rd31, 28;
	@%p30 bra 	$L__BB0_55;
	add.s64 	%rd231, %rd32, 4;
	setp.ge.u64 	%p31, %rd231, %rd15;
	@%p31 bra 	$L__BB0_53;
	add.s64 	%rd232, %rd17, %rd31;
	ld.local.u8 	%r136, [%rd232+2];
	cvt.u32.u16 	%r137, %rs118;
	and.b32  	%r138, %r137, 255;
	mad.lo.s32 	%r139, %r138, %r22, %r136;
	cvt.u64.u32 	%rd233, %r139;
	add.s64 	%rd235, %rd42, %rd233;
	ld.shared.u8 	%rs118, [%rd235+260];
	bra.uni 	$L__BB0_53;
$L__BB0_55:
	sub.s32 	%r140, %r13, %r18;
	shr.u32 	%r21, %r140, 5;
	st.shared.u8 	[%rd13], %rs118;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p32, %r5, %r21;
	@%p32 bra 	$L__BB0_77;
	bra.uni 	$L__BB0_56;
$L__BB0_77:
	ld.shared.u8 	%r141, [%rd13+1];
	cvt.u32.u16 	%r142, %rs118;
	and.b32  	%r143, %r142, 255;
	mad.lo.s32 	%r144, %r143, %r22, %r141;
	cvt.u64.u32 	%rd236, %r144;
	add.s64 	%rd238, %rd42, %rd236;
	ld.shared.u8 	%rs118, [%rd238+260];
$L__BB0_56:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs118;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p33, %r6, %r21;
	@%p33 bra 	$L__BB0_78;
	bra.uni 	$L__BB0_57;
$L__BB0_78:
	ld.shared.u8 	%r145, [%rd13+2];
	cvt.u32.u16 	%r146, %rs118;
	and.b32  	%r147, %r146, 255;
	mad.lo.s32 	%r148, %r147, %r22, %r145;
	cvt.u64.u32 	%rd239, %r148;
	add.s64 	%rd241, %rd42, %rd239;
	ld.shared.u8 	%rs118, [%rd241+260];
$L__BB0_57:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs118;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p34, %r7, %r21;
	@%p34 bra 	$L__BB0_79;
	bra.uni 	$L__BB0_58;
$L__BB0_79:
	ld.shared.u8 	%r149, [%rd13+4];
	cvt.u32.u16 	%r150, %rs118;
	and.b32  	%r151, %r150, 255;
	mad.lo.s32 	%r152, %r151, %r22, %r149;
	cvt.u64.u32 	%rd242, %r152;
	add.s64 	%rd244, %rd42, %rd242;
	ld.shared.u8 	%rs118, [%rd244+260];
$L__BB0_58:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs118;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p35, %r8, %r21;
	@%p35 bra 	$L__BB0_80;
	bra.uni 	$L__BB0_59;
$L__BB0_80:
	ld.shared.u8 	%r153, [%rd13+8];
	cvt.u32.u16 	%r154, %rs118;
	and.b32  	%r155, %r154, 255;
	mad.lo.s32 	%r156, %r155, %r22, %r153;
	cvt.u64.u32 	%rd245, %r156;
	add.s64 	%rd247, %rd42, %rd245;
	ld.shared.u8 	%rs118, [%rd247+260];
$L__BB0_59:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs118;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p36, %r9, %r21;
	@%p36 bra 	$L__BB0_81;
	bra.uni 	$L__BB0_60;
$L__BB0_81:
	ld.shared.u8 	%r157, [%rd13+16];
	cvt.u32.u16 	%r158, %rs118;
	and.b32  	%r159, %r158, 255;
	mad.lo.s32 	%r160, %r159, %r22, %r157;
	cvt.u64.u32 	%rd248, %r160;
	add.s64 	%rd250, %rd42, %rd248;
	ld.shared.u8 	%rs118, [%rd250+260];
$L__BB0_60:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs118;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p37, %r10, %r21;
	@%p37 bra 	$L__BB0_82;
	bra.uni 	$L__BB0_61;
$L__BB0_82:
	ld.shared.u8 	%r161, [%rd13+32];
	cvt.u32.u16 	%r162, %rs118;
	and.b32  	%r163, %r162, 255;
	mad.lo.s32 	%r164, %r163, %r22, %r161;
	cvt.u64.u32 	%rd251, %r164;
	add.s64 	%rd253, %rd42, %rd251;
	ld.shared.u8 	%rs118, [%rd253+260];
$L__BB0_61:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs118;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p38, %r11, %r21;
	@%p38 bra 	$L__BB0_83;
	bra.uni 	$L__BB0_62;
$L__BB0_83:
	ld.shared.u8 	%r165, [%rd13+64];
	cvt.u32.u16 	%r166, %rs118;
	and.b32  	%r167, %r166, 255;
	mad.lo.s32 	%r168, %r167, %r22, %r165;
	cvt.u64.u32 	%rd254, %r168;
	add.s64 	%rd256, %rd42, %rd254;
	ld.shared.u8 	%rs118, [%rd256+260];
$L__BB0_62:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs118;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p39, %r12, %r21;
	@%p39 bra 	$L__BB0_84;
	bra.uni 	$L__BB0_63;
$L__BB0_84:
	ld.shared.u8 	%r169, [%rd13+128];
	cvt.u32.u16 	%r170, %rs118;
	and.b32  	%r171, %r170, 255;
	mad.lo.s32 	%r172, %r171, %r22, %r169;
	cvt.u64.u32 	%rd257, %r172;
	add.s64 	%rd259, %rd42, %rd257;
	ld.shared.u8 	%rs118, [%rd259+260];
$L__BB0_63:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs118;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p40, %r14, %r21;
	@%p40 bra 	$L__BB0_65;
	bra.uni 	$L__BB0_64;
$L__BB0_65:
	ld.shared.u8 	%r173, [%rd13+256];
	cvt.u32.u16 	%r174, %rs118;
	and.b32  	%r175, %r174, 255;
	mad.lo.s32 	%r176, %r175, %r22, %r173;
	cvt.u64.u32 	%rd260, %r176;
	add.s64 	%rd262, %rd42, %rd260;
	ld.shared.u8 	%rs118, [%rd262+260];
$L__BB0_64:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd13], %rs118;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	bra.uni 	$L__BB0_40;
$L__BB0_41:
	st.local.u8 	[%rd3], %rs3;
	cvt.u64.u32 	%rd263, %r17;
	add.s64 	%rd264, %rd36, %rd263;
	ld.shared.u8 	%rs98, [match_$_initial_storage+14660];
	st.global.u8 	[%rd264], %rs98;
	bra.uni 	$L__BB0_6;
$L__BB0_8:
	st.local.u8 	[%rd3], %rs3;
	ret;

}
	// .globl	reduce
.visible .entry reduce(
	.param .u64 reduce_param_0,
	.param .u32 reduce_param_1,
	.param .u64 reduce_param_2,
	.param .u32 reduce_param_3,
	.param .u64 reduce_param_4
)
{
	.local .align 16 .b8 	__local_depot1[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<34>;
	.reg .b16 	%rs<83>;
	.reg .b32 	%r<127>;
	.reg .b64 	%rd<152>;

	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r11, [reduce_param_3];
	ld.param.u32 	%r10, [reduce_param_1];
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mul.lo.s32 	%r3, %r10, %r10;
	setp.ge.u32 	%p1, %r1, %r3;
	cvt.u64.u32 	%rd145, %r1;
	mov.u64 	%rd146, match_$_initial_storage;
	@%p1 bra 	$L__BB1_3;
	ld.param.u64 	%rd27, [reduce_param_0];
	add.s64 	%rd148, %rd27, %rd145;
	add.s64 	%rd34, %rd145, %rd146;
	add.s64 	%rd147, %rd34, 260;
	mov.u32 	%r126, %r1;
$L__BB1_2:
	ld.global.u8 	%rs51, [%rd148];
	st.shared.u8 	[%rd147], %rs51;
	add.s32 	%r126, %r126, 512;
	add.s64 	%rd148, %rd148, 512;
	add.s64 	%rd147, %rd147, 512;
	setp.lt.u32 	%p2, %r126, %r3;
	@%p2 bra 	$L__BB1_2;
$L__BB1_3:
	ld.param.u64 	%rd28, [reduce_param_2];
	// begin inline asm
	bar.sync 0;
	// end inline asm
	shl.b32 	%r6, %r2, 14;
	add.s32 	%r12, %r6, 16384;
	setp.le.u32 	%p3, %r12, %r11;
	shl.b32 	%r13, %r1, 5;
	add.s32 	%r14, %r6, %r13;
	cvt.u64.u32 	%rd9, %r14;
	@%p3 bra 	$L__BB1_13;
	add.u64 	%rd1, %SPL, 0;
	cvt.u64.u32 	%rd10, %r11;
	add.s64 	%rd87, %rd9, %rd28;
	add.s64 	%rd11, %rd87, 1;
	mov.u64 	%rd17, 0;
	bra.uni 	$L__BB1_5;
$L__BB1_29:
	add.s64 	%rd17, %rd17, 4;
	setp.eq.s64 	%p18, %rd17, 32;
	@%p18 bra 	$L__BB1_30;
$L__BB1_5:
	add.s64 	%rd18, %rd9, %rd17;
	setp.lt.u64 	%p14, %rd18, %rd10;
	add.s64 	%rd19, %rd11, %rd17;
	add.s64 	%rd20, %rd1, %rd17;
	@%p14 bra 	$L__BB1_6;
	bra.uni 	$L__BB1_7;
$L__BB1_6:
	ld.global.u8 	%rs54, [%rd19+-1];
	st.local.u8 	[%rd20], %rs54;
$L__BB1_7:
	add.s64 	%rd88, %rd18, 1;
	setp.ge.u64 	%p15, %rd88, %rd10;
	@%p15 bra 	$L__BB1_9;
	ld.global.u8 	%rs55, [%rd19];
	st.local.u8 	[%rd20+1], %rs55;
$L__BB1_9:
	add.s64 	%rd89, %rd18, 2;
	setp.ge.u64 	%p16, %rd89, %rd10;
	@%p16 bra 	$L__BB1_11;
	ld.global.u8 	%rs56, [%rd19+1];
	st.local.u8 	[%rd20+2], %rs56;
$L__BB1_11:
	add.s64 	%rd90, %rd18, 3;
	setp.ge.u64 	%p17, %rd90, %rd10;
	@%p17 bra 	$L__BB1_29;
	ld.global.u8 	%rs57, [%rd19+2];
	st.local.u8 	[%rd20+3], %rs57;
	bra.uni 	$L__BB1_29;
$L__BB1_13:
	add.u64 	%rd31, %SP, 32;
	add.u64 	%rd2, %SPL, 32;
	mov.u64 	%rd149, 0;
	add.s64 	%rd36, %rd28, %rd9;
	ld.global.u64 	%rd37, [%rd36+8];
	or.b64  	%rd39, %rd31, 8;
	st.u64 	[%rd39], %rd37;
	ld.global.u64 	%rd40, [%rd36+24];
	st.u64 	[%SP+56], %rd40;
	ld.global.u64 	%rd41, [%rd36+16];
	st.u64 	[%SP+48], %rd41;
	ld.global.u64 	%rd42, [%rd36];
	st.u64 	[%SP+32], %rd42;
	ld.local.u8 	%rs59, [%rd2];
	add.s64 	%rd45, %rd146, 260;
$L__BB1_14:
	add.s64 	%rd14, %rd2, %rd149;
	ld.local.u8 	%r15, [%rd14+1];
	cvt.u32.u16 	%r16, %rs59;
	and.b32  	%r17, %r16, 255;
	mad.lo.s32 	%r18, %r17, %r10, %r15;
	cvt.u64.u32 	%rd43, %r18;
	add.s64 	%rd46, %rd45, %rd43;
	ld.shared.u8 	%r19, [%rd46];
	ld.local.v2.u8 	{%rs52, %rs53}, [%rd14+2];
	cvt.u32.u16 	%r20, %rs52;
	mad.lo.s32 	%r21, %r19, %r10, %r20;
	cvt.u64.u32 	%rd47, %r21;
	add.s64 	%rd48, %rd45, %rd47;
	ld.shared.u8 	%r22, [%rd48];
	cvt.u32.u16 	%r23, %rs53;
	mad.lo.s32 	%r24, %r22, %r10, %r23;
	cvt.u64.u32 	%rd49, %r24;
	add.s64 	%rd50, %rd45, %rd49;
	ld.shared.u8 	%rs60, [%rd50];
	cvt.u32.u16 	%r25, %rs60;
	and.b32  	%r7, %r25, 255;
	setp.eq.s64 	%p4, %rd149, 28;
	@%p4 bra 	$L__BB1_16;
	add.s64 	%rd149, %rd149, 4;
	ld.local.u8 	%r26, [%rd14+4];
	mad.lo.s32 	%r27, %r7, %r10, %r26;
	cvt.u64.u32 	%rd51, %r27;
	add.s64 	%rd53, %rd146, %rd51;
	ld.shared.u8 	%rs59, [%rd53+260];
	bra.uni 	$L__BB1_14;
$L__BB1_30:
	ld.local.u8 	%rs74, [%rd1];
	add.s64 	%rd21, %rd1, 2;
	mov.u64 	%rd23, 0;
	bra.uni 	$L__BB1_31;
$L__BB1_39:
	add.s64 	%rd23, %rd23, 4;
$L__BB1_31:
	add.s64 	%rd24, %rd9, %rd23;
	add.s64 	%rd92, %rd24, 1;
	setp.lt.u64 	%p19, %rd92, %rd10;
	@%p19 bra 	$L__BB1_40;
	bra.uni 	$L__BB1_32;
$L__BB1_40:
	add.s64 	%rd93, %rd21, %rd23;
	ld.local.u8 	%r63, [%rd93+-1];
	cvt.u32.u16 	%r64, %rs74;
	and.b32  	%r65, %r64, 255;
	mad.lo.s32 	%r66, %r65, %r10, %r63;
	cvt.u64.u32 	%rd94, %r66;
	add.s64 	%rd96, %rd146, %rd94;
	ld.shared.u8 	%rs74, [%rd96+260];
$L__BB1_32:
	add.s64 	%rd97, %rd24, 2;
	setp.ge.u64 	%p20, %rd97, %rd10;
	@%p20 bra 	$L__BB1_34;
	add.s64 	%rd98, %rd21, %rd23;
	ld.local.u8 	%r67, [%rd98];
	cvt.u32.u16 	%r68, %rs74;
	and.b32  	%r69, %r68, 255;
	mad.lo.s32 	%r70, %r69, %r10, %r67;
	cvt.u64.u32 	%rd99, %r70;
	add.s64 	%rd101, %rd146, %rd99;
	ld.shared.u8 	%rs74, [%rd101+260];
$L__BB1_34:
	add.s64 	%rd102, %rd24, 3;
	setp.ge.u64 	%p21, %rd102, %rd10;
	@%p21 bra 	$L__BB1_36;
	add.s64 	%rd103, %rd21, %rd23;
	ld.local.u8 	%r71, [%rd103+1];
	cvt.u32.u16 	%r72, %rs74;
	and.b32  	%r73, %r72, 255;
	mad.lo.s32 	%r74, %r73, %r10, %r71;
	cvt.u64.u32 	%rd104, %r74;
	add.s64 	%rd106, %rd146, %rd104;
	ld.shared.u8 	%rs74, [%rd106+260];
$L__BB1_36:
	setp.eq.s64 	%p22, %rd23, 28;
	@%p22 bra 	$L__BB1_41;
	add.s64 	%rd107, %rd24, 4;
	setp.ge.u64 	%p23, %rd107, %rd10;
	@%p23 bra 	$L__BB1_39;
	add.s64 	%rd108, %rd21, %rd23;
	ld.local.u8 	%r75, [%rd108+2];
	cvt.u32.u16 	%r76, %rs74;
	and.b32  	%r77, %r76, 255;
	mad.lo.s32 	%r78, %r77, %r10, %r75;
	cvt.u64.u32 	%rd109, %r78;
	add.s64 	%rd111, %rd146, %rd109;
	ld.shared.u8 	%rs74, [%rd111+260];
	bra.uni 	$L__BB1_39;
$L__BB1_16:
	add.s64 	%rd56, %rd146, %rd145;
	add.s64 	%rd16, %rd56, 14660;
	st.shared.u8 	[%rd56+14660], %rs60;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p5, %r1, 511;
	@%p5 bra 	$L__BB1_53;
	bra.uni 	$L__BB1_17;
$L__BB1_53:
	ld.shared.u8 	%r28, [%rd16+1];
	mad.lo.s32 	%r29, %r7, %r10, %r28;
	cvt.u64.u32 	%rd57, %r29;
	add.s64 	%rd59, %rd146, %rd57;
	ld.shared.u8 	%rs60, [%rd59+260];
$L__BB1_17:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd16], %rs60;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p6, %r1, 510;
	@%p6 bra 	$L__BB1_54;
	bra.uni 	$L__BB1_18;
$L__BB1_54:
	ld.shared.u8 	%r30, [%rd16+2];
	cvt.u32.u16 	%r31, %rs60;
	and.b32  	%r32, %r31, 255;
	mad.lo.s32 	%r33, %r32, %r10, %r30;
	cvt.u64.u32 	%rd60, %r33;
	add.s64 	%rd62, %rd146, %rd60;
	ld.shared.u8 	%rs60, [%rd62+260];
$L__BB1_18:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd16], %rs60;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p7, %r1, 508;
	@%p7 bra 	$L__BB1_55;
	bra.uni 	$L__BB1_19;
$L__BB1_55:
	ld.shared.u8 	%r34, [%rd16+4];
	cvt.u32.u16 	%r35, %rs60;
	and.b32  	%r36, %r35, 255;
	mad.lo.s32 	%r37, %r36, %r10, %r34;
	cvt.u64.u32 	%rd63, %r37;
	add.s64 	%rd65, %rd146, %rd63;
	ld.shared.u8 	%rs60, [%rd65+260];
$L__BB1_19:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd16], %rs60;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p8, %r1, 504;
	@%p8 bra 	$L__BB1_56;
	bra.uni 	$L__BB1_20;
$L__BB1_56:
	ld.shared.u8 	%r38, [%rd16+8];
	cvt.u32.u16 	%r39, %rs60;
	and.b32  	%r40, %r39, 255;
	mad.lo.s32 	%r41, %r40, %r10, %r38;
	cvt.u64.u32 	%rd66, %r41;
	add.s64 	%rd68, %rd146, %rd66;
	ld.shared.u8 	%rs60, [%rd68+260];
$L__BB1_20:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd16], %rs60;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p9, %r1, 496;
	@%p9 bra 	$L__BB1_57;
	bra.uni 	$L__BB1_21;
$L__BB1_57:
	ld.shared.u8 	%r42, [%rd16+16];
	cvt.u32.u16 	%r43, %rs60;
	and.b32  	%r44, %r43, 255;
	mad.lo.s32 	%r45, %r44, %r10, %r42;
	cvt.u64.u32 	%rd69, %r45;
	add.s64 	%rd71, %rd146, %rd69;
	ld.shared.u8 	%rs60, [%rd71+260];
$L__BB1_21:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd16], %rs60;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p10, %r1, 480;
	@%p10 bra 	$L__BB1_58;
	bra.uni 	$L__BB1_22;
$L__BB1_58:
	ld.shared.u8 	%r46, [%rd16+32];
	cvt.u32.u16 	%r47, %rs60;
	and.b32  	%r48, %r47, 255;
	mad.lo.s32 	%r49, %r48, %r10, %r46;
	cvt.u64.u32 	%rd72, %r49;
	add.s64 	%rd74, %rd146, %rd72;
	ld.shared.u8 	%rs60, [%rd74+260];
$L__BB1_22:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd16], %rs60;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p11, %r1, 448;
	@%p11 bra 	$L__BB1_59;
	bra.uni 	$L__BB1_23;
$L__BB1_59:
	ld.shared.u8 	%r50, [%rd16+64];
	cvt.u32.u16 	%r51, %rs60;
	and.b32  	%r52, %r51, 255;
	mad.lo.s32 	%r53, %r52, %r10, %r50;
	cvt.u64.u32 	%rd75, %r53;
	add.s64 	%rd77, %rd146, %rd75;
	ld.shared.u8 	%rs60, [%rd77+260];
$L__BB1_23:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd16], %rs60;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p12, %r1, 384;
	@%p12 bra 	$L__BB1_60;
	bra.uni 	$L__BB1_24;
$L__BB1_60:
	ld.shared.u8 	%r54, [%rd16+128];
	cvt.u32.u16 	%r55, %rs60;
	and.b32  	%r56, %r55, 255;
	mad.lo.s32 	%r57, %r56, %r10, %r54;
	cvt.u64.u32 	%rd78, %r57;
	add.s64 	%rd80, %rd146, %rd78;
	ld.shared.u8 	%rs60, [%rd80+260];
$L__BB1_24:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd16], %rs60;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	setp.lt.u32 	%p13, %r1, 256;
	@%p13 bra 	$L__BB1_28;
	bra.uni 	$L__BB1_25;
$L__BB1_28:
	or.b32  	%r58, %r1, 256;
	cvt.u64.u32 	%rd81, %r58;
	add.s64 	%rd83, %rd146, %rd81;
	ld.shared.u8 	%r59, [%rd83+14660];
	cvt.u32.u16 	%r60, %rs60;
	and.b32  	%r61, %r60, 255;
	mad.lo.s32 	%r62, %r61, %r10, %r59;
	cvt.u64.u32 	%rd84, %r62;
	add.s64 	%rd85, %rd146, %rd84;
	ld.shared.u8 	%rs60, [%rd85+260];
$L__BB1_25:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd16], %rs60;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	bra.uni 	$L__BB1_26;
$L__BB1_41:
	sub.s32 	%r79, %r11, %r6;
	add.s32 	%r80, %r79, 31;
	shr.u32 	%r9, %r80, 5;
	add.s64 	%rd114, %rd146, %rd145;
	add.s64 	%rd25, %rd114, 14660;
	st.shared.u8 	[%rd114+14660], %rs74;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	add.s32 	%r81, %r1, 1;
	setp.lt.u32 	%p24, %r81, %r9;
	@%p24 bra 	$L__BB1_61;
	bra.uni 	$L__BB1_42;
$L__BB1_61:
	ld.shared.u8 	%r82, [%rd25+1];
	cvt.u32.u16 	%r83, %rs74;
	and.b32  	%r84, %r83, 255;
	mad.lo.s32 	%r85, %r84, %r10, %r82;
	cvt.u64.u32 	%rd115, %r85;
	add.s64 	%rd117, %rd146, %rd115;
	ld.shared.u8 	%rs74, [%rd117+260];
$L__BB1_42:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd25], %rs74;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	add.s32 	%r86, %r1, 2;
	setp.lt.u32 	%p25, %r86, %r9;
	@%p25 bra 	$L__BB1_62;
	bra.uni 	$L__BB1_43;
$L__BB1_62:
	ld.shared.u8 	%r87, [%rd25+2];
	cvt.u32.u16 	%r88, %rs74;
	and.b32  	%r89, %r88, 255;
	mad.lo.s32 	%r90, %r89, %r10, %r87;
	cvt.u64.u32 	%rd118, %r90;
	add.s64 	%rd120, %rd146, %rd118;
	ld.shared.u8 	%rs74, [%rd120+260];
$L__BB1_43:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd25], %rs74;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	add.s32 	%r91, %r1, 4;
	setp.lt.u32 	%p26, %r91, %r9;
	@%p26 bra 	$L__BB1_63;
	bra.uni 	$L__BB1_44;
$L__BB1_63:
	ld.shared.u8 	%r92, [%rd25+4];
	cvt.u32.u16 	%r93, %rs74;
	and.b32  	%r94, %r93, 255;
	mad.lo.s32 	%r95, %r94, %r10, %r92;
	cvt.u64.u32 	%rd121, %r95;
	add.s64 	%rd123, %rd146, %rd121;
	ld.shared.u8 	%rs74, [%rd123+260];
$L__BB1_44:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd25], %rs74;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	add.s32 	%r96, %r1, 8;
	setp.lt.u32 	%p27, %r96, %r9;
	@%p27 bra 	$L__BB1_64;
	bra.uni 	$L__BB1_45;
$L__BB1_64:
	ld.shared.u8 	%r97, [%rd25+8];
	cvt.u32.u16 	%r98, %rs74;
	and.b32  	%r99, %r98, 255;
	mad.lo.s32 	%r100, %r99, %r10, %r97;
	cvt.u64.u32 	%rd124, %r100;
	add.s64 	%rd126, %rd146, %rd124;
	ld.shared.u8 	%rs74, [%rd126+260];
$L__BB1_45:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd25], %rs74;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	add.s32 	%r101, %r1, 16;
	setp.lt.u32 	%p28, %r101, %r9;
	@%p28 bra 	$L__BB1_65;
	bra.uni 	$L__BB1_46;
$L__BB1_65:
	ld.shared.u8 	%r102, [%rd25+16];
	cvt.u32.u16 	%r103, %rs74;
	and.b32  	%r104, %r103, 255;
	mad.lo.s32 	%r105, %r104, %r10, %r102;
	cvt.u64.u32 	%rd127, %r105;
	add.s64 	%rd129, %rd146, %rd127;
	ld.shared.u8 	%rs74, [%rd129+260];
$L__BB1_46:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd25], %rs74;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	add.s32 	%r106, %r1, 32;
	setp.lt.u32 	%p29, %r106, %r9;
	@%p29 bra 	$L__BB1_66;
	bra.uni 	$L__BB1_47;
$L__BB1_66:
	ld.shared.u8 	%r107, [%rd25+32];
	cvt.u32.u16 	%r108, %rs74;
	and.b32  	%r109, %r108, 255;
	mad.lo.s32 	%r110, %r109, %r10, %r107;
	cvt.u64.u32 	%rd130, %r110;
	add.s64 	%rd132, %rd146, %rd130;
	ld.shared.u8 	%rs74, [%rd132+260];
$L__BB1_47:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd25], %rs74;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	add.s32 	%r111, %r1, 64;
	setp.lt.u32 	%p30, %r111, %r9;
	@%p30 bra 	$L__BB1_67;
	bra.uni 	$L__BB1_48;
$L__BB1_67:
	ld.shared.u8 	%r112, [%rd25+64];
	cvt.u32.u16 	%r113, %rs74;
	and.b32  	%r114, %r113, 255;
	mad.lo.s32 	%r115, %r114, %r10, %r112;
	cvt.u64.u32 	%rd133, %r115;
	add.s64 	%rd135, %rd146, %rd133;
	ld.shared.u8 	%rs74, [%rd135+260];
$L__BB1_48:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd25], %rs74;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	add.s32 	%r116, %r1, 128;
	setp.lt.u32 	%p31, %r116, %r9;
	@%p31 bra 	$L__BB1_68;
	bra.uni 	$L__BB1_49;
$L__BB1_68:
	ld.shared.u8 	%r117, [%rd25+128];
	cvt.u32.u16 	%r118, %rs74;
	and.b32  	%r119, %r118, 255;
	mad.lo.s32 	%r120, %r119, %r10, %r117;
	cvt.u64.u32 	%rd136, %r120;
	add.s64 	%rd138, %rd146, %rd136;
	ld.shared.u8 	%rs74, [%rd138+260];
$L__BB1_49:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd25], %rs74;
	// begin inline asm
	bar.sync 0;
	// end inline asm
	add.s32 	%r121, %r1, 256;
	setp.lt.u32 	%p32, %r121, %r9;
	@%p32 bra 	$L__BB1_51;
	bra.uni 	$L__BB1_50;
$L__BB1_51:
	ld.shared.u8 	%r122, [%rd25+256];
	cvt.u32.u16 	%r123, %rs74;
	and.b32  	%r124, %r123, 255;
	mad.lo.s32 	%r125, %r124, %r10, %r122;
	cvt.u64.u32 	%rd139, %r125;
	add.s64 	%rd141, %rd146, %rd139;
	ld.shared.u8 	%rs74, [%rd141+260];
$L__BB1_50:
	// begin inline asm
	bar.sync 0;
	// end inline asm
	st.shared.u8 	[%rd25], %rs74;
	// begin inline asm
	bar.sync 0;
	// end inline asm
$L__BB1_26:
	setp.eq.s32 	%p33, %r1, 0;
	@%p33 bra 	$L__BB1_52;
	bra.uni 	$L__BB1_27;
$L__BB1_52:
	ld.param.u64 	%rd29, [reduce_param_4];
	cvt.u64.u32 	%rd142, %r2;
	add.s64 	%rd12, %rd29, %rd142;
	ld.shared.u8 	%rs58, [match_$_initial_storage+14660];
	st.global.u8 	[%rd12], %rs58;
$L__BB1_27:
	ret;

}
